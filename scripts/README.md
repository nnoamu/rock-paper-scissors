# Scripts

Python szkriptek dataset kezelÃ©shez, model training-hez Ã©s tesztelÃ©shez.

## StruktÃºra

```
scripts/
â”œâ”€â”€ data/              # Dataset kezelÃ©s
â”‚   â”œâ”€â”€ download_dataset.py
â”‚   â”œâ”€â”€ dataset_info.py
â”‚   â””â”€â”€ create_splits.py
â”œâ”€â”€ training/          # Model training
â”‚   â””â”€â”€ mediapipe/
â”‚       â””â”€â”€ train_rf.py
â””â”€â”€ tests/             # Tesztek
    â””â”€â”€ mediapipe/
        â”œâ”€â”€ test_model.py
        â””â”€â”€ ...
```

---

# Dataset Management (data/)

## ğŸ“¥ Dataset LetÃ¶ltÃ©s

```bash
# ElÃ©rhetÅ‘ forrÃ¡sok listÃ¡zÃ¡sa
venv/bin/python scripts/data/download_dataset.py --list

# LetÃ¶ltÃ©s Kaggle-rÅ‘l
venv/bin/python scripts/data/download_dataset.py --source kaggle-drgfreeman
venv/bin/python scripts/data/download_dataset.py --source kaggle-sanikamal

# Custom output mappa
venv/bin/python scripts/data/download_dataset.py --source kaggle-drgfreeman --output data/custom
```

**ElÃ©rhetÅ‘ forrÃ¡sok:**
- `kaggle-drgfreeman`: 2188 kÃ©p, vÃ¡ltozatos hÃ¡ttÃ©r
- `kaggle-sanikamal`: 2520 kÃ©p, egyszerÅ± hÃ¡ttÃ©r

## ğŸ“Š Dataset InformÃ¡ciÃ³k

```bash
# StatisztikÃ¡k: kÃ©pszÃ¡m, formÃ¡tumok, osztÃ¡ly eloszlÃ¡s
venv/bin/python scripts/data/dataset_info.py

# Custom mappa
venv/bin/python scripts/data/dataset_info.py --data data/custom
```

## ğŸ”€ Train/Val/Test Split

```bash
# AlapÃ©rtelmezett: 70% train, 10% val, 20% test
venv/bin/python scripts/data/create_splits.py

# Custom arÃ¡nyok
venv/bin/python scripts/data/create_splits.py --test-size 0.15 --val-size 0.15

# Custom output
venv/bin/python scripts/data/create_splits.py --output data/splits/custom_split.json
```

**Output:** `data/splits/split_indices.json`

## ğŸ”§ Ãšj Dataset ForrÃ¡s HozzÃ¡adÃ¡sa

1. KÃ©szÃ­ts Ãºj downloader-t: `scripts/downloaders/my_downloader.py`

```python
from .base_downloader import BaseDownloader

class MyDownloader(BaseDownloader):
    def download(self, target_dir: str) -> bool:
        # ImplementÃ¡ciÃ³
        return True
    
    def get_description(self) -> str:
        return "Dataset leÃ­rÃ¡s"
```

2. RegisztrÃ¡ld `download_dataset.py`-ban:

```python
DOWNLOADERS = {
    'my-source': lambda: MyDownloader(),
}
```

3. HasznÃ¡lat:

```bash
python scripts/download_dataset.py --source my-source
```

## ğŸ“ MappastruktÃºra

```
scripts/
â”œâ”€â”€ download_dataset.py      # FÅ‘ orchestrator
â”œâ”€â”€ dataset_info.py           # StatisztikÃ¡k
â”œâ”€â”€ create_splits.py          # Split lÃ©trehozÃ¡s
â”œâ”€â”€ downloaders/
â”‚   â”œâ”€â”€ base_downloader.py    # Base osztÃ¡ly
â”‚   â””â”€â”€ kaggle_downloader.py  # Kaggle implementÃ¡ciÃ³
â””â”€â”€ utils/
    â””â”€â”€ dataset_organizer.py  # KÃ¶zÃ¶s szervezÅ‘ logika
```

## âš™ï¸ KÃ¶vetelmÃ©nyek

```bash
pip install kagglehub scikit-learn
```

**Kaggle API config:** `~/.kaggle/kaggle.json`

LetÃ¶ltÃ©s: https://www.kaggle.com/settings â†’ Create API Token

---

# Model Training (training/)

## MediaPipe + Random Forest

```bash
# Train model (outputs: models/rf_mediapipe.pkl + features)
venv/bin/python scripts/training/mediapipe/train_rf.py
```

**Output:**
- `models/rf_mediapipe.pkl` - Trained Random Forest model
- `data/mediapipe_features/*.npy` - Extracted features for reuse

---

# Testing (tests/)

## MediaPipe Tests

```bash
# Model accuracy test
venv/bin/python scripts/tests/mediapipe/test_model.py --num-samples 20

# Full pipeline integration test
venv/bin/python scripts/tests/mediapipe/test_integration.py

# Check failed detections
venv/bin/python scripts/tests/mediapipe/check_failed_images.py

# Debug specific image
venv/bin/python scripts/tests/mediapipe/debug_hand_detection.py data/raw/rock/rock_0001.png

# Analyze detection issues
venv/bin/python scripts/tests/mediapipe/visualize_detection_issue.py data/raw/rock/rock_0009.png
```

RÃ©szletek: `scripts/tests/mediapipe/README.md`